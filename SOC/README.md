###### tags: `Практика`
# Security Operations Center
[**Операционный центр безопасности**](https://) - это централизованное подразделение, которое занимается вопросами безопасности на организационном и техническом уровне. Он состоит из трех строительных блоков: людей, процессов и технологий для управления и повышения уровня безопасности организации.

Сегодня вопросами построения **Security Operation Center (SOC)** интересуются практически все представители отечественной экономики: от страховых компаний и банков до крупных промышленных предприятий. Такой интерес вызван прежде всего постоянно совершенствующимися атаками и потребностью в современном инструменте противодействия им. Действительно, SOC является одним из ключевых компонентов подразделения информационной безопасности любой организации. В первую очередь он нацелен на мониторинг, детектирование и оперативную реакцию на инциденты, и, как следствие, на сокращение ущерба и финансовых потерь, к которым тот или иной инцидент может привести.

Функции SOC на основе классификации [MITRE](https://www.mitre.org/sites/default/files/publications/pr-13-1028-mitre-10-strategies-cyber-ops-center.pdf):

![](https://i.imgur.com/xgMuwFt.jpg)


## Используемые инструменты
* [Elasticsearch](https://ru.wikipedia.org/wiki/Elasticsearch)
* Logstash
* Kibana

**ELK** — это аббревиатура из названий трех продуктов: Elasticsearch, Logstash и Kibana. Это три продукта с открытым кодом, которые в некоторый момент времени стали принадлежать одной компании и развиваться в одном направлении. Итак, для чего же они нужны.

**Logstash** — это инструмент получения, преобразования и сохранения данных в общем хранилище. Его первой задачей является прием данных в каком-либо виде: из файла, базы данных, логов или информационных каналов. Далее полученная информация может модифицироваться с помощью фильтров, например, единая строка может быть разбита на поля, могут добавляться или изменяться данные, несколько строк могут агрегироваться и т.п. Обработанная информация посылается в системы — потребители этой информации. Говоря о связке ELK, потребителем информации будет Elasticsearch, однако возможны другие варианты, например системы мониторинга и управления (Nagios, Jira и др.), системы хранения информации (Google Cloud Storage, syslog и др.), файлы на диске. Возможен даже запуск команды при получении особого набора данных.

**Elasticsearch** — это собственно механизм индексирования и хранения полученной информации, а также полнотекстового поиска по ней. Он основан на библиотеке Apache Lucene и, по сути, является NoSQL database решением. Главная задача этого инструмента — организация быстрого и гибкого поиска по полученным данным. Для ее решения имеется возможность выбора анализаторов текста, функционал «нечеткого поиска», поддерживается поиск по информации на восточных языках (корейский, китайский, японский). Работа с информацией происходит с помощью REST API, который позволяет добавлять, просматривать, модифицировать и удалять данные. Однако в случае использования ELK этот вопрос остается внутри «черной коробочки», поскольку у нас есть уже выше описанный Logstash и Kibana.

**Kibana** — это user friendly интерфейс, для Elasticsearch, который имеет большое количество возможностей по поиску данных в дебрях индексов Elasticsearch и отображению этих данных в удобочитаемых видах  таблиц, графиков и диаграмм.

Таким образом, связка ELK является достаточно мощным инструментом сбора и аналитики информации.
## Инструкция по установке
### Загрузка
```
git clone https://github.com/Ivanhahanov/InformtionsSecurityMethodsAndTools.git
```
### Развертывание
Переходим в директорию SOC:
```shell
cd SOC
```
Для начала запустим ELK стек:
```
docker-compose up -d elasticsearch logstash kibana 
```
Затем ждём, пока всё запустится. Можно проверить, что всё готово разными способами:
1. Посмотреть логи 
```
docker-compose logs -f
```
2. Посмотреть процессы
```
docker-compose ps
```
После того как ELK-стек запустился, надо запустить сервис с формой ввода логина и пароля:
```
docker-compose up service
```
## Инструкция по выполнению

Теперь у нас развёрнута инфраструктура состоящая из: базы данных(Elasticsearch), сервиса для сбора логов(Logstash), сервиса для визуализации данных(Kibana) и сайт c формой входа.

Сервис уже автоматически пишет все свои логи в Logstash, а тот в свою очередь пишет Elasticsearch. Визуализацию логов можно посмотреть использую Kibana.

1. Зайти в [Kibana](http://localhost:5601) по адресу http://localhost:5601

```shell
Логин: elsatic
Пароль: changeme
```
После ввода логина и пароля вы должны увидеть такое окно:

![](https://i.imgur.com/BjkTVnb.png)
Добро пожаловать в Kibana

Теперь давайте попробуем воспользоваться нашим сервисом с формой

2. Переходим по адресу http://localhost:8080.

Вы должны увидеть вот такую, простую форму ввода.

![](https://i.imgur.com/2dklWaA.png)

Пароль по умолчанию **admin:admin**.

Создайте активность путём ввода различных учётных данных.

Теперь давайте посмотрим, записались ли в логи наши действия в базу данных.

3. Откройте выпадающие меню и выберите Stack Management, а затем Index patterns.

![](https://i.imgur.com/1PeyjSM.png)

![](https://i.imgur.com/MuQ3Z8L.png)

4. Создайте индекс с помощью маски logstash-*.

![](https://i.imgur.com/ep7kWZm.png)

5. В поле "Time Filed" укажите `@timestamp`.

![](https://i.imgur.com/Aw3uHGn.png)

![](https://i.imgur.com/lTouFDP.png)

После того, как создался Паттерн, давайте взглянем на наши данные.
Для этого нам нужен модуль **Discover**.

6. Выбираем **Discover** в главном меню.

![](https://i.imgur.com/VAdNS47.png)

![](https://i.imgur.com/26CyCo3.png)

Здесь мы видим наши запросы.

Доступные поля, на которые стоит обратить внимание:
* `rAddr` - IP адрес с которого был отправлен запрос
* `login` - Введённые логи
* `hashPassword` - Хэшированный пароль
* `route` - URL сервера к которому был отправлен запрос
* `message` - Сообщение сервиса
* `level` - тип сообщений (warning, info)

7. Давайте сгенерируем данные для дальнейшего анализа.

Для этого запустим программу, которая будет отправлять запросы от различных пользователей .
```
./usersSimulation
```
Данная программа эмулирует активность различных пользователей и выполняет следующие функции: 
* Отправляет запросы на регистрацию от различных пользователей
* Эмулирует действия злоумышленника, который пытается подобрать пароль

Программа будет работать до тех пор, пока её не остановить с помощью сочетания клавиш `Ctrl-C`

Чем больше программа будет работать тем больше будет различных запросов для анализа.

Время работы программы определите сами и укажите это время в отчёте.

8. С помощью различных средств визуализации, создайте себе среду для анализа трафика

![](https://i.imgur.com/IavEBxl.png)

На выбор имеется огромное количество различных средств визуализации данных, на любой вкус и цвет.

![](https://i.imgur.com/73LkLNI.png)

С помощью этих средств вам необходимо определить следующие параметры:
* IP адрес злоумышленника
* Количество запросов злоумышленника
* Количество легитимных пользователей системы

## Отчёт
Варианты сдачи, на усмотрение преподавателя
1. Сформировать отчёт в формате .pdf, указать время работы `usersSimulation` и приложить туда скрины Dashboard'ов, с помощью которых был определён IP адрес злоумышленника, количество запросов злоумышленника и количество легитимных пользователей системы.   
2. Предоставить всё вышеперечисленное преподавателю и ответить на каверзные вопросы :-)

## Полезные сслыки
* [Гайд от MITRE](https://www.mitre.org/sites/default/files/publications/pr-13-1028-mitre-10-strategies-cyber-ops-center.pdf) англ.
* [Перевод гайда](https://rvision.pro/10-strategij-pervoklassnogo-soc-perevod-gajda-mitre/) рус.
